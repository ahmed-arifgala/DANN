{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8845748,"sourceType":"datasetVersion","datasetId":5324072}],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch.utils.data as data\nfrom PIL import Image\nimport os\nimport torch.backends.cudnn as cudnn\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-06T18:21:21.852576Z","iopub.execute_input":"2024-07-06T18:21:21.852961Z","iopub.status.idle":"2024-07-06T18:21:24.917154Z","shell.execute_reply.started":"2024-07-06T18:21:21.852927Z","shell.execute_reply":"2024-07-06T18:21:24.916360Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"os.environ['CUDA_LAUNCH_BLOCKING'] = '1'","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:24.918489Z","iopub.execute_input":"2024-07-06T18:21:24.918855Z","iopub.status.idle":"2024-07-06T18:21:24.923158Z","shell.execute_reply.started":"2024-07-06T18:21:24.918830Z","shell.execute_reply":"2024-07-06T18:21:24.922113Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# import torchvision.models as models\n\n# # Load AlexNet\n# alexnet = models.alexnet(pretrained=True)\n\n# # Print model summary\n# print(alexnet)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:27.329588Z","iopub.execute_input":"2024-07-06T18:21:27.329927Z","iopub.status.idle":"2024-07-06T18:21:27.335966Z","shell.execute_reply.started":"2024-07-06T18:21:27.329902Z","shell.execute_reply":"2024-07-06T18:21:27.335105Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# features = alexnet.features.children\n# print(features)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:28.265547Z","iopub.execute_input":"2024-07-06T18:21:28.265903Z","iopub.status.idle":"2024-07-06T18:21:28.270169Z","shell.execute_reply.started":"2024-07-06T18:21:28.265875Z","shell.execute_reply":"2024-07-06T18:21:28.269051Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# # Calculate mean and standard deviation\n# data = mnist_data.data.numpy().astype(np.float32) / 255.0\n# mean = np.mean(data)\n# std = np.std(data)\n\n# print('mean: ', mean)\n# print('std: ', std)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:28.729198Z","iopub.execute_input":"2024-07-06T18:21:28.729527Z","iopub.status.idle":"2024-07-06T18:21:28.733568Z","shell.execute_reply.started":"2024-07-06T18:21:28.729502Z","shell.execute_reply":"2024-07-06T18:21:28.732664Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Check if CUDA (GPU support) is available\nimport torch\ncuda = torch.cuda.is_available()\n\n# Print whether CUDA is available\nprint('CUDA available:', cuda)\n\ndevice = torch.device('cuda' if cuda else 'cpu')\nprint(\"device: \", device)\n\nif cuda:\n    cudnn.benchmark = True","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:29.447542Z","iopub.execute_input":"2024-07-06T18:21:29.447883Z","iopub.status.idle":"2024-07-06T18:21:29.482185Z","shell.execute_reply.started":"2024-07-06T18:21:29.447856Z","shell.execute_reply":"2024-07-06T18:21:29.481208Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"CUDA available: True\ndevice:  cuda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Preprocessing","metadata":{}},{"cell_type":"code","source":"import os\nimport torch.backends.cudnn as cudnn\nimport torch.utils.data\nfrom torchvision import transforms\nfrom torchvision import datasets\nimport random\nimport torch.optim as optim\nimport numpy as np","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:30.538831Z","iopub.execute_input":"2024-07-06T18:21:30.539489Z","iopub.status.idle":"2024-07-06T18:21:32.041977Z","shell.execute_reply.started":"2024-07-06T18:21:30.539458Z","shell.execute_reply":"2024-07-06T18:21:32.041196Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"#data file names\nsource_dataset_name = 'source_domain'\ntarget_dataset_name = 'target_domain'\n\n#folders that contain the image foldes and label text files\nsource_image_root = os.path.join('/kaggle/input/plantvillage-dann/Plantvillage_Dataset', source_dataset_name)\ntarget_image_root = os.path.join('/kaggle/input/plantvillage-dann/Plantvillage_Dataset', target_dataset_name)\n\n#dir where model is to be stored\nmodel_root = os.path.join('/kaggle/working', 'models')\n\n#hyperparameters\ncuda = True\ncudnn.benchmark = True\nlr = 1e-3\nbatch_size = 32\nimage_size = 128 \nn_epoch = 100\n\nmanual_seed = random.randint(1, 10000)\nrandom.seed(manual_seed)\ntorch.manual_seed(manual_seed)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:32.043341Z","iopub.execute_input":"2024-07-06T18:21:32.043867Z","iopub.status.idle":"2024-07-06T18:21:32.054582Z","shell.execute_reply.started":"2024-07-06T18:21:32.043840Z","shell.execute_reply":"2024-07-06T18:21:32.053561Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7c6bfe3df6f0>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Data Loader","metadata":{}},{"cell_type":"code","source":"## custom data loader function to load the data and apply the transformation\n\n#   def __init__(self, data_root, data_list, transform=None, domain=None):\n        \nclass GetLoader(data.Dataset):\n    def __init__(self, data_root, data_list, transform=None):\n        self.root = data_root ## data image folder\n        self.transform = transform \n#         self.domain = domain\n\n        ## read label txt file\n        f = open(data_list, 'r')\n        data_list = f.readlines()\n        f.close()\n\n        self.n_data = len(data_list)\n\n        self.img_paths = []\n        self.img_labels = []\n\n        for line in data_list:\n            img_file, label = line.strip().split(' ', 1)\n            self.img_paths.append(img_file)\n            self.img_labels.append(label)\n            \n\n    def __getitem__(self, item):\n        img_paths, labels = self.img_paths[item], self.img_labels[item]\n        imgs = Image.open(os.path.join(self.root, img_paths)).convert('RGB')\n\n#         if self.domain == 'source':\n#             imgs = imgs.convert('RGB')\n#         elif self.domain == 'target':\n#             imgs = imgs.convert('L')\n#         else:\n#             print('Error! Incorrect domain name.')\n            \n            \n        if self.transform is not None:\n            imgs = self.transform(imgs)\n            labels = int(labels)\n\n        return imgs, labels\n\n    def __len__(self):\n        return self.n_data","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:35.948961Z","iopub.execute_input":"2024-07-06T18:21:35.949698Z","iopub.status.idle":"2024-07-06T18:21:35.958555Z","shell.execute_reply.started":"2024-07-06T18:21:35.949669Z","shell.execute_reply":"2024-07-06T18:21:35.957545Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"## Fetch data label\n\n# source domain\nlabel_list_source = os.path.join(target_image_root, 'train_labels.txt')\n\n# target domain\nlabel_list_target = os.path.join(target_image_root, 'train_labels.txt')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:36.680553Z","iopub.execute_input":"2024-07-06T18:21:36.681274Z","iopub.status.idle":"2024-07-06T18:21:36.685933Z","shell.execute_reply.started":"2024-07-06T18:21:36.681244Z","shell.execute_reply":"2024-07-06T18:21:36.684787Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"## Standardization","metadata":{}},{"cell_type":"code","source":"##Standardization function\n\ndef calculate_mean_std(loader):\n    \n    ##initializing accumulaters\n    mean = 0.0\n    std = 0.0\n    total_images_count = 0\n\n    for images, _ in loader: # loader returns the images and the labels for each batch\n        images_count_in_a_batch = images.size(0) #returns the batch size shape(batch_size, channels, height, width)\n        images = images.view(images_count_in_a_batch, images.size(1), -1) #reshape the image (batch_size, channel, flattened)\n        mean += images.mean(2).sum(0) #takes mean at the flattened dim and sums for all the images in the batch\n        std += images.std(2).sum(0) \n        total_images_count += images_count_in_a_batch \n\n    mean /= total_images_count #to calc avg mean\n    std /= total_images_count #to calc avg std\n\n    return mean, std\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:37.677136Z","iopub.execute_input":"2024-07-06T18:21:37.677464Z","iopub.status.idle":"2024-07-06T18:21:37.683912Z","shell.execute_reply.started":"2024-07-06T18:21:37.677441Z","shell.execute_reply":"2024-07-06T18:21:37.683002Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"\n\n# Temporary transform for calculating mean and std\ntemp_transform = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor()\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:38.070899Z","iopub.execute_input":"2024-07-06T18:21:38.071516Z","iopub.status.idle":"2024-07-06T18:21:38.076058Z","shell.execute_reply.started":"2024-07-06T18:21:38.071484Z","shell.execute_reply":"2024-07-06T18:21:38.075032Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"# Source Domain\ntemp_dataset_source = GetLoader(\n                                data_root = os.path.join(source_image_root, 'train'),\n                                data_list = label_list_source,\n                                transform = temp_transform,\n#                                 domain = 'source'\n                               )\n\ntemp_loader_source = torch.utils.data.DataLoader(\n                                temp_dataset_source, \n                                batch_size=batch_size, \n                                shuffle=True, \n                                num_workers=4\n                                )\n\n# Target Domain\ntemp_dataset_target = GetLoader(\n                                data_root=os.path.join(target_image_root, 'train'), \n                                data_list=label_list_target, \n                                transform=temp_transform,\n#                                 domain = 'target'\n                                )\n\ntemp_loader_target = torch.utils.data.DataLoader(\n                                temp_dataset_target, \n                                batch_size=batch_size, \n                                shuffle=True, \n                                num_workers=4\n                                )\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:38.538675Z","iopub.execute_input":"2024-07-06T18:21:38.539365Z","iopub.status.idle":"2024-07-06T18:21:38.706873Z","shell.execute_reply.started":"2024-07-06T18:21:38.539335Z","shell.execute_reply":"2024-07-06T18:21:38.706122Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"mean_source, std_source = calculate_mean_std(temp_loader_source)\nmean_target, std_target = calculate_mean_std(temp_loader_target)\n\n\n# mean_source = [0.4666, 0.4894, 0.4106]\n# std_source = [0.1542, 0.1256, 0.1727]\n# mean_target = [0.4718]\n# std_target = [0.1345]\n\n# # Print results\nprint(f\"Source Mean: {mean_source}, Source Std: {std_source}\")\nprint(f\"Target Mean: {mean_target}, Target Std: {std_target}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:21:39.095016Z","iopub.execute_input":"2024-07-06T18:21:39.095867Z","iopub.status.idle":"2024-07-06T18:25:45.035840Z","shell.execute_reply.started":"2024-07-06T18:21:39.095837Z","shell.execute_reply":"2024-07-06T18:25:45.034727Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Source Mean: tensor([0.4671, 0.4899, 0.4111]), Source Std: tensor([0.1659, 0.1381, 0.1833])\nTarget Mean: tensor([0.4723, 0.4723, 0.4723]), Target Std: tensor([0.1463, 0.1463, 0.1463])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"\n### Loading data after standardization","metadata":{}},{"cell_type":"code","source":"## Define final transformer\n\nimg_transform_source = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean_source, std=std_source)\n])\n\nimg_transform_target = transforms.Compose([\n    transforms.Resize(image_size),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=mean_target, std=std_target)\n])","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.038349Z","iopub.execute_input":"2024-07-06T18:25:45.039178Z","iopub.status.idle":"2024-07-06T18:25:45.044826Z","shell.execute_reply.started":"2024-07-06T18:25:45.039147Z","shell.execute_reply":"2024-07-06T18:25:45.043968Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"## Loading Source Data\n\n\ndataset_source = GetLoader(\n    data_root=os.path.join(source_image_root, 'train'), #folder that contains the data images\n    data_list=label_list_source,#label text file\n    transform=img_transform_source #transformation\n)\n\ndataloader_source = torch.utils.data.DataLoader(\n    dataset=dataset_source,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.045860Z","iopub.execute_input":"2024-07-06T18:25:45.046169Z","iopub.status.idle":"2024-07-06T18:25:45.104703Z","shell.execute_reply.started":"2024-07-06T18:25:45.046145Z","shell.execute_reply":"2024-07-06T18:25:45.103711Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"## Loading Target Data\n\ndataset_target = GetLoader(\n    data_root=os.path.join(target_image_root, 'train'), #folder that contains the data images\n    data_list=label_list_target,#label text file\n    transform=img_transform_target #transformation\n)\n\ndataloader_target = torch.utils.data.DataLoader(\n    dataset=dataset_target,\n    batch_size=batch_size,\n    shuffle=True,\n    num_workers=4)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.106740Z","iopub.execute_input":"2024-07-06T18:25:45.107018Z","iopub.status.idle":"2024-07-06T18:25:45.154492Z","shell.execute_reply.started":"2024-07-06T18:25:45.106994Z","shell.execute_reply":"2024-07-06T18:25:45.153809Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"from torch.autograd import Function","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.155416Z","iopub.execute_input":"2024-07-06T18:25:45.155644Z","iopub.status.idle":"2024-07-06T18:25:45.159730Z","shell.execute_reply.started":"2024-07-06T18:25:45.155624Z","shell.execute_reply":"2024-07-06T18:25:45.158787Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class ReverseLayerF(Function):\n\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n\n        return output, None","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.160882Z","iopub.execute_input":"2024-07-06T18:25:45.161191Z","iopub.status.idle":"2024-07-06T18:25:45.170492Z","shell.execute_reply.started":"2024-07-06T18:25:45.161156Z","shell.execute_reply":"2024-07-06T18:25:45.169581Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nimport torchvision.models as models\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.171408Z","iopub.execute_input":"2024-07-06T18:25:45.171636Z","iopub.status.idle":"2024-07-06T18:25:45.180014Z","shell.execute_reply.started":"2024-07-06T18:25:45.171616Z","shell.execute_reply":"2024-07-06T18:25:45.179094Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# class CNNModel(nn.Module):\n\n#     def __init__(self):\n#         super(CNNModel, self).__init__()\n#         self.feature = nn.Sequential()\n#         self.feature.add_module('f_conv1', nn.Conv2d(3, 64, kernel_size=5))\n#         self.feature.add_module('f_bn1', nn.BatchNorm2d(64))\n#         self.feature.add_module('f_pool1', nn.MaxPool2d(2))\n#         self.feature.add_module('f_relu1', nn.ReLU(True))\n#         self.feature.add_module('f_conv2', nn.Conv2d(64, 50, kernel_size=5))\n#         self.feature.add_module('f_bn2', nn.BatchNorm2d(50))\n#         self.feature.add_module('f_drop1', nn.Dropout())\n#         self.feature.add_module('f_pool2', nn.MaxPool2d(2))\n#         self.feature.add_module('f_relu2', nn.ReLU(True))\n\n#         self.class_classifier = nn.Sequential()\n#         self.class_classifier.add_module('c_fc1', nn.Linear(50 * 4 * 4, 100))\n#         self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(100))\n#         self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n#         self.class_classifier.add_module('c_drop1', nn.Dropout())\n#         self.class_classifier.add_module('c_fc2', nn.Linear(100, 100))\n#         self.class_classifier.add_module('c_bn2', nn.BatchNorm1d(100))\n#         self.class_classifier.add_module('c_relu2', nn.ReLU(True))\n#         self.class_classifier.add_module('c_fc3', nn.Linear(100, 38))\n#         self.class_classifier.add_module('c_softmax', nn.LogSoftmax())\n\n#         self.domain_classifier = nn.Sequential()\n#         self.domain_classifier.add_module('d_fc1', nn.Linear(50 * 4 * 4, 100))\n#         self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(100))\n#         self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n#         self.domain_classifier.add_module('d_fc2', nn.Linear(100, 2))\n#         self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n\n#     def forward(self, input_data, alpha):\n#         input_data = input_data.expand(input_data.data.shape[0], 3, 28, 28)\n#         feature = self.feature(input_data)\n#         feature = feature.view(-1, 50 * 4 * 4)\n#         reverse_feature = ReverseLayerF.apply(feature, alpha)\n#         class_output = self.class_classifier(feature)\n#         domain_output = self.domain_classifier(reverse_feature)\n\n#         return class_output, domain_output","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.181245Z","iopub.execute_input":"2024-07-06T18:25:45.181547Z","iopub.status.idle":"2024-07-06T18:25:45.189917Z","shell.execute_reply.started":"2024-07-06T18:25:45.181523Z","shell.execute_reply":"2024-07-06T18:25:45.188988Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"class CNNModel(nn.Module):\n    def __init__(self):\n        super(CNNModel, self).__init__()\n        \n        # Defining the feature extractor part\n        self.feature = nn.Sequential()\n        self.feature.add_module('f_conv1', nn.Conv2d(3, 32, kernel_size=3))  \n        self.feature.add_module('f_bn1', nn.BatchNorm2d(32))  # BatchNorm after Conv layer\n        self.feature.add_module('f_pool1', nn.MaxPool2d(kernel_size=2, stride=2))\n        self.feature.add_module('f_relu1', nn.ReLU(True))\n        \n        self.feature.add_module('f_conv2', nn.Conv2d(32, 16, kernel_size=3))\n        self.feature.add_module('f_bn2', nn.BatchNorm2d(16))  # BatchNorm after Conv layer\n        self.feature.add_module('f_pool2', nn.MaxPool2d(kernel_size=2, stride=2))\n        self.feature.add_module('f_relu2', nn.ReLU(True))\n        \n        self.feature.add_module('f_conv3', nn.Conv2d(16, 8, kernel_size=3))\n        self.feature.add_module('f_bn3', nn.BatchNorm2d(8))  # BatchNorm after Conv layer\n        self.feature.add_module('f_pool3', nn.MaxPool2d(kernel_size=2, stride=2))\n        self.feature.add_module('f_relu3', nn.ReLU(True))\n\n        # Classifier for class prediction\n        self.class_classifier = nn.Sequential()\n        self.class_classifier.add_module('c_fc1', nn.Linear(8 * 14 * 14, 128))  # Adjust based on flattened input\n        self.class_classifier.add_module('c_bn1', nn.BatchNorm1d(128))  # BatchNorm after FC layer\n        self.class_classifier.add_module('c_relu1', nn.ReLU(True))\n        \n        self.class_classifier.add_module('c_fc2', nn.Linear(128, 38))  # 38 classes\n        self.class_classifier.add_module('c_softmax', nn.LogSoftmax(dim=1))\n        \n        # Classifier for domain prediction (DANN)\n        self.domain_classifier = nn.Sequential()\n        self.domain_classifier.add_module('d_fc1', nn.Linear(8 * 14 * 14, 128))  # Same input size\n        self.domain_classifier.add_module('d_bn1', nn.BatchNorm1d(128))  # BatchNorm after FC layer\n        self.domain_classifier.add_module('d_relu1', nn.ReLU(True))\n        \n        self.domain_classifier.add_module('d_fc2', nn.Linear(128, 2))  # Assuming binary domain classification\n        self.domain_classifier.add_module('d_softmax', nn.LogSoftmax(dim=1))\n\n    def forward(self, input_data, alpha):\n        # Assuming the input is already 1x128x128\n        input_data = input_data.expand(input_data.data.shape[0], 3, 128, 128)\n\n            \n        feature = self.feature(input_data)\n        feature = feature.view(-1, 8 * 14 * 14)  # Flattening the feature map\n        \n        # Gradient reversal layer\n        reverse_feature = ReverseLayerF.apply(feature, alpha)\n        \n        # Class and domain classification outputs\n        class_output = self.class_classifier(feature)\n        domain_output = self.domain_classifier(reverse_feature)\n        \n        return class_output, domain_output","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:25:45.191324Z","iopub.execute_input":"2024-07-06T18:25:45.191642Z","iopub.status.idle":"2024-07-06T18:25:45.210169Z","shell.execute_reply.started":"2024-07-06T18:25:45.191613Z","shell.execute_reply":"2024-07-06T18:25:45.209053Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# class CNNModel(nn.Module):\n#     def __init__(self):\n#         super(CNNModel, self).__init__()\n        \n#         # Load pre-trained AlexNet without the final classification layer\n#         alexnet = models.alexnet(pretrained=False)\n#         self.feature_extractor = nn.Sequential(*list(alexnet.features.children()))\n\n#         # Class classifier\n#         self.class_classifier = nn.Sequential(\n#             nn.Linear(256 * 6 * 6, 4096),  # Adjust input size according to feature extractor output\n#             nn.ReLU(True),\n#             nn.Dropout(0.3),\n#             nn.Linear(4096, 4096),\n#             nn.ReLU(True),\n#             nn.Dropout(),\n#             nn.Linear(4096, 38),  # Number of classes in your specific task\n#             nn.LogSoftmax(dim=1)\n#         )\n\n#         # Domain classifier\n#         self.domain_classifier = nn.Sequential(\n#             nn.Linear(256 * 6 * 6, 1024),  # Adjust input size according to feature extractor output\n#             nn.ReLU(True),\n#             nn.Dropout(0.3),\n#             nn.Linear(1024, 1024),\n#             nn.ReLU(True),\n#             nn.Dropout(0.3),\n#             nn.Linear(1024, 2),  # Binary classification: source or target domain\n#             nn.LogSoftmax(dim=1)\n#         )\n\n#     def forward(self, input_data, alpha):\n        \n#         input_data = input_data.expand(input_data.data.shape[0], 3, 224, 224)\n\n#         # Feature extraction through AlexNet\n#         features = self.feature_extractor(input_data)\n#         features = features.view(-1, 256 * 6 * 6)  # Flatten the feature map\n\n#         # Reverse features for domain classification\n#         reverse_features = ReverseLayerF.apply(features, alpha)\n\n#         # Get class and domain outputs\n#         class_output = self.class_classifier(features)\n#         domain_output = self.domain_classifier(reverse_features)\n\n#         return class_output, domain_output\n","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:02:57.088855Z","iopub.execute_input":"2024-07-06T15:02:57.089223Z","iopub.status.idle":"2024-07-06T15:02:57.095053Z","shell.execute_reply.started":"2024-07-06T15:02:57.089194Z","shell.execute_reply":"2024-07-06T15:02:57.094069Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Test Function","metadata":{}},{"cell_type":"code","source":"\ndef test(dataset_name, epoch):\n    assert dataset_name in ['source_domain', 'target_domain']\n\n#     model_root = os.path.join('/kaggle/working', 'models')\n\n    image_root = os.path.join('/kaggle/input/plantvillage-dann/Plantvillage_Dataset', dataset_name)\n    \n    cudnn.benchmark = True\n    batch_size = 32\n    image_size = 128\n    alpha = 0\n\n    \"\"\"load data\"\"\"\n\n    img_transform_source = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean_source, std=std_source)\n    ])\n\n    img_transform_target = transforms.Compose([\n        transforms.Resize(image_size),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=mean_target, std=std_target)\n    ])\n        \n    test_list = os.path.join(image_root, 'test_labels.txt')\n\n    dataset = GetLoader(\n        data_root=os.path.join(image_root, 'test'),\n        data_list=test_list,\n        transform=img_transform_source if dataset_name == 'source_domain' else img_transform_target\n    )\n        \n\n    dataloader = torch.utils.data.DataLoader(\n        dataset=dataset,\n        batch_size=batch_size,\n        shuffle=False,\n        num_workers=8\n    )\n\n    \"\"\" training \"\"\"\n\n    my_net = torch.load(os.path.join(\n        model_root, 'plantvillage_model_epoch_' + str(epoch) + '.pth'\n    ))\n    my_net = my_net.eval()\n\n    if cuda:\n        my_net = my_net.cuda()\n\n    len_dataloader = len(dataloader)\n    data_target_iter = iter(dataloader)\n\n    i = 0\n    n_total = 0\n    n_correct = 0\n    total_loss = 0  # Initialize total loss\n\n\n    while i < len_dataloader:\n\n        # test model using target data\n        data_target = next(data_target_iter)\n        t_img, t_label = data_target\n\n        batch_size = len(t_label)\n\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n\n        if cuda:\n            t_img = t_img.cuda()\n            t_label = t_label.cuda()\n            input_img = input_img.cuda()\n            class_label = class_label.cuda()\n\n        input_img.resize_as_(t_img).copy_(t_img)\n        class_label.resize_as_(t_label).copy_(t_label)\n\n        ##run model\n        class_output, _ = my_net(input_data=input_img, alpha=alpha)\n        \n        ##calc loss\n        err_test_label = loss_class(class_output, class_label)\n        \n        total_loss += err_test_label.item()  # Accumulate the loss\n\n        \n        ##calc acc\n        pred = class_output.data.max(1, keepdim=True)[1]\n        n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum().item()\n        n_total += batch_size\n\n        i += 1\n        \n    avg_loss = total_loss / len_dataloader  # Compute average loss\n    accu = n_correct / n_total\n\n#     print('epoch: %d, accuracy of the %s dataset: %f' % (epoch, dataset_name, accu))\n    \n    return avg_loss, accu","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:02:57.950242Z","iopub.execute_input":"2024-07-06T15:02:57.951187Z","iopub.status.idle":"2024-07-06T15:02:57.965829Z","shell.execute_reply.started":"2024-07-06T15:02:57.951151Z","shell.execute_reply":"2024-07-06T15:02:57.964939Z"},"trusted":true},"execution_count":63,"outputs":[]},{"cell_type":"markdown","source":"## Main","metadata":{}},{"cell_type":"code","source":"print(os.listdir(target_image_root))","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:02:58.651824Z","iopub.execute_input":"2024-07-06T15:02:58.652442Z","iopub.status.idle":"2024-07-06T15:02:58.666221Z","shell.execute_reply.started":"2024-07-06T15:02:58.652413Z","shell.execute_reply":"2024-07-06T15:02:58.665312Z"},"trusted":true},"execution_count":64,"outputs":[{"name":"stdout","text":"['train_labels.txt', 'test', 'test_labels.txt', 'train']\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Load Model","metadata":{}},{"cell_type":"code","source":"my_net = CNNModel()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:02:59.281530Z","iopub.execute_input":"2024-07-06T15:02:59.281916Z","iopub.status.idle":"2024-07-06T15:02:59.296052Z","shell.execute_reply.started":"2024-07-06T15:02:59.281889Z","shell.execute_reply":"2024-07-06T15:02:59.295131Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"# setup optimizer\n\noptimizer = optim.Adam(my_net.parameters(), lr=lr)\n\nloss_class = torch.nn.NLLLoss()\nloss_domain = torch.nn.NLLLoss()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:02:59.652331Z","iopub.execute_input":"2024-07-06T15:02:59.653003Z","iopub.status.idle":"2024-07-06T15:02:59.659318Z","shell.execute_reply.started":"2024-07-06T15:02:59.652968Z","shell.execute_reply":"2024-07-06T15:02:59.658381Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"if cuda:\n    my_net = my_net.cuda()\n    loss_class = loss_class.cuda()\n    loss_domain = loss_domain.cuda()\n\nfor p in my_net.parameters():\n    p.requires_grad = True","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:02:59.957630Z","iopub.execute_input":"2024-07-06T15:02:59.958008Z","iopub.status.idle":"2024-07-06T15:02:59.965842Z","shell.execute_reply.started":"2024-07-06T15:02:59.957979Z","shell.execute_reply":"2024-07-06T15:02:59.965026Z"},"trusted":true},"execution_count":67,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(model_root):\n    os.makedirs(model_root)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:03:00.311252Z","iopub.execute_input":"2024-07-06T15:03:00.312565Z","iopub.status.idle":"2024-07-06T15:03:00.317677Z","shell.execute_reply.started":"2024-07-06T15:03:00.312522Z","shell.execute_reply":"2024-07-06T15:03:00.316717Z"},"trusted":true},"execution_count":68,"outputs":[]},{"cell_type":"code","source":"print(n_epoch)","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:03:00.620332Z","iopub.execute_input":"2024-07-06T15:03:00.620710Z","iopub.status.idle":"2024-07-06T15:03:00.625831Z","shell.execute_reply.started":"2024-07-06T15:03:00.620676Z","shell.execute_reply":"2024-07-06T15:03:00.624776Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"100\n","output_type":"stream"}]},{"cell_type":"code","source":"# training\n\n# Initialize lists to store metrics\ntrain_losses_s_label = []\ntrain_losses_s_domain = []\ntrain_losses_t_domain = []\ntrain_accs = []\ntest_losses_source = []\ntest_accs_source = []\ntest_losses_target = []\ntest_accs_target = []\n\nprint('TRAINING STARTED...')\n\nfor epoch in range(1, n_epoch + 1):\n\n    \n    len_dataloader = min(len(dataloader_source), len(dataloader_target)) ##returns the number of batches to find the min no of batches\n    data_source_iter = iter(dataloader_source) ##initialize iterator\n    data_target_iter = iter(dataloader_target)\n\n    # Initialize accumulators for the losses\n    total_err_s_label = 0\n    total_err_s_domain = 0\n    total_err_t_domain = 0\n    total_correct = 0\n    total_samples = 0\n    \n    i = 0\n    while i < len_dataloader: ##run iterations equal to the number of batches\n\n        p = float(i + epoch * len_dataloader) / n_epoch / len_dataloader\n        alpha = 2. / (1. + np.exp(-10 * p)) - 1\n\n        # training model using SOURCE DATA \n        \n        data_source = next(data_source_iter) ##fetch the next batch of data\n        s_img, s_label = data_source ## returns the images and their corresponding labels\n\n        my_net.zero_grad() ## resets the gradient to remove gradients of previous batches\n        batch_size = len(s_label)\n\n        ##initialize variables\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        class_label = torch.LongTensor(batch_size)\n        domain_label = torch.zeros(batch_size) ##to zero becz it is source domain\n        domain_label = domain_label.long()\n        \n#         print(type(input_img))\n#         print(type(class_label))\n#         print(type(domain_label))\n\n        if cuda:\n             # Check tensor types and shapes before transferring to CUDA\n#             print(type(s_img), s_img.size(), s_img.dtype)\n#             print(type(s_label), s_label.size(), s_label.dtype)\n    \n            s_img = s_img.cuda()\n            s_label = s_label.cuda()\n            input_img = input_img.cuda()\n            class_label = class_label.cuda()\n            domain_label = domain_label.cuda()\n\n        input_img.resize_as_(s_img).copy_(s_img)\n        class_label.resize_as_(s_label).copy_(s_label)\n\n        ##train the model\n        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n        \n        ##calc errors\n        err_s_label = loss_class(class_output, class_label) ##classification error\n        err_s_domain = loss_domain(domain_output, domain_label) ##domain error\n\n        \n        # training model using TARGET DATA\n        data_target = next(data_target_iter) ##fetches the next batch\n        t_img, _ = data_target ##returns the images but not the labels as to do unsupervised learning\n\n#         print(type(t_img))\n\n        batch_size = len(t_img)\n\n        ##initialize variables\n        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n        domain_label = torch.ones(batch_size) ##one becz its target domain\n        domain_label = domain_label.long()\n\n        if cuda:\n            t_img = t_img.cuda()\n            input_img = input_img.cuda()\n            domain_label = domain_label.cuda()\n\n        input_img.resize_as_(t_img).copy_(t_img)\n\n        ##train the model\n        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n        \n        ##calc error\n        err_t_domain = loss_domain(domain_output, domain_label)\n        err = err_t_domain + err_s_domain + err_s_label\n        \n        \n        err.backward()\n        optimizer.step()\n\n        # Accumulate the losses\n        total_err_s_label += err_s_label.item() # Convert tensor to Python number and accumulate\n        total_err_s_domain += err_s_domain.item()\n        total_err_t_domain += err_t_domain.item()\n        \n        # Calculate accuracy for source data\n        pred = class_output.data.max(1, keepdim=True)[1]\n        total_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum().item()\n        total_samples += batch_size\n        \n        i += 1\n\n    # Calculate the average losses\n    avg_err_s_label = total_err_s_label / len_dataloader\n    avg_err_s_domain = total_err_s_domain / len_dataloader\n    avg_err_t_domain = total_err_t_domain / len_dataloader\n    avg_accuracy = total_correct / total_samples\n\n    # Append to lists for graph\n    train_losses_s_label.append(avg_err_s_label)\n    train_losses_s_domain.append(avg_err_s_domain)\n    train_losses_t_domain.append(avg_err_t_domain)\n    train_accs.append(avg_accuracy)\n    \n    # Print training metrics\n    print('\\nepoch: ', epoch)\n    print('\\tTrain:')\n    print('\\t\\terr_s_label: %f, err_s_domain: %f, err_t_domain: %f, accuracy: %f' %\n          (avg_err_s_label, avg_err_s_domain, avg_err_t_domain, avg_accuracy))\n    \n\n    torch.save(my_net, '{0}/plantvillage_model_epoch_{1}.pth'.format(model_root, epoch))\n   \n    test_loss_source, test_acc_source = test(source_dataset_name, epoch)\n    test_loss_target, test_acc_target = test(target_dataset_name, epoch)\n\n    # Append test metrics\n    test_losses_source.append(test_loss_source)\n    test_accs_source.append(test_acc_source)\n    \n    test_losses_target.append(test_loss_target)\n    test_accs_target.append(test_acc_target)\n    \n    # Print test metrics\n    print('\\tTest:')\n    print('\\t\\tSource dataset -  loss: %f, accuracy: %f' % (test_loss_source, test_acc_source))\n    print('\\t\\tTarget dataset -  loss: %f, accuracy: %f' % (test_loss_target, test_acc_target))\n\n    \n    \nprint('TRAINING COMPLETED')","metadata":{"execution":{"iopub.status.busy":"2024-07-06T15:03:00.971220Z","iopub.execute_input":"2024-07-06T15:03:00.971874Z","iopub.status.idle":"2024-07-06T17:44:28.371867Z","shell.execute_reply.started":"2024-07-06T15:03:00.971842Z","shell.execute_reply":"2024-07-06T17:44:28.370482Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stdout","text":"TRAINING STARTED...\n\nepoch:  1\n\tTrain:\n\t\terr_s_label: 0.832499, err_s_domain: 0.455985, err_t_domain: 0.459501, accuracy: 0.773078\n\tTest:\n\t\tSource dataset -  loss: 1.135997, accuracy: 0.681776\n\t\tTarget dataset -  loss: 3.571404, accuracy: 0.285307\n\nepoch:  2\n\tTrain:\n\t\terr_s_label: 0.362530, err_s_domain: 0.331890, err_t_domain: 0.329320, accuracy: 0.888968\n\tTest:\n\t\tSource dataset -  loss: 1.039398, accuracy: 0.709728\n\t\tTarget dataset -  loss: 3.094813, accuracy: 0.332935\n\nepoch:  3\n\tTrain:\n\t\terr_s_label: 0.267090, err_s_domain: 0.338506, err_t_domain: 0.337036, accuracy: 0.917037\n\tTest:\n\t\tSource dataset -  loss: 1.496645, accuracy: 0.638746\n\t\tTarget dataset -  loss: 3.374304, accuracy: 0.377896\n\nepoch:  4\n\tTrain:\n\t\terr_s_label: 0.237948, err_s_domain: 0.392760, err_t_domain: 0.394185, accuracy: 0.924244\n\tTest:\n\t\tSource dataset -  loss: 2.070968, accuracy: 0.579257\n\t\tTarget dataset -  loss: 2.707807, accuracy: 0.449522\n\nepoch:  5\n\tTrain:\n\t\terr_s_label: 0.223246, err_s_domain: 0.464158, err_t_domain: 0.469485, accuracy: 0.927698\n\tTest:\n\t\tSource dataset -  loss: 1.289597, accuracy: 0.709912\n\t\tTarget dataset -  loss: 2.899205, accuracy: 0.439500\n\nepoch:  6\n\tTrain:\n\t\terr_s_label: 0.201732, err_s_domain: 0.482834, err_t_domain: 0.486885, accuracy: 0.932534\n\tTest:\n\t\tSource dataset -  loss: 1.266274, accuracy: 0.712946\n\t\tTarget dataset -  loss: 2.383154, accuracy: 0.514160\n\nepoch:  7\n\tTrain:\n\t\terr_s_label: 0.199046, err_s_domain: 0.506839, err_t_domain: 0.509611, accuracy: 0.933109\n\tTest:\n\t\tSource dataset -  loss: 1.164661, accuracy: 0.728393\n\t\tTarget dataset -  loss: 2.220759, accuracy: 0.558753\n\nepoch:  8\n\tTrain:\n\t\terr_s_label: 0.195843, err_s_domain: 0.558133, err_t_domain: 0.559858, accuracy: 0.935642\n\tTest:\n\t\tSource dataset -  loss: 0.961028, accuracy: 0.758367\n\t\tTarget dataset -  loss: 2.778292, accuracy: 0.534296\n\nepoch:  9\n\tTrain:\n\t\terr_s_label: 0.186105, err_s_domain: 0.594606, err_t_domain: 0.597741, accuracy: 0.938820\n\tTest:\n\t\tSource dataset -  loss: 1.534724, accuracy: 0.665042\n\t\tTarget dataset -  loss: 1.694549, accuracy: 0.618150\n\nepoch:  10\n\tTrain:\n\t\terr_s_label: 0.176040, err_s_domain: 0.618988, err_t_domain: 0.621004, accuracy: 0.941905\n\tTest:\n\t\tSource dataset -  loss: 0.631433, accuracy: 0.826499\n\t\tTarget dataset -  loss: 1.284671, accuracy: 0.712026\n\nepoch:  11\n\tTrain:\n\t\terr_s_label: 0.163872, err_s_domain: 0.636533, err_t_domain: 0.637810, accuracy: 0.944231\n\tTest:\n\t\tSource dataset -  loss: 0.617105, accuracy: 0.834314\n\t\tTarget dataset -  loss: 1.515689, accuracy: 0.677455\n\nepoch:  12\n\tTrain:\n\t\terr_s_label: 0.149339, err_s_domain: 0.649351, err_t_domain: 0.650143, accuracy: 0.949043\n\tTest:\n\t\tSource dataset -  loss: 0.557892, accuracy: 0.848750\n\t\tTarget dataset -  loss: 1.227332, accuracy: 0.727841\n\nepoch:  13\n\tTrain:\n\t\terr_s_label: 0.135499, err_s_domain: 0.654954, err_t_domain: 0.655288, accuracy: 0.953994\n\tTest:\n\t\tSource dataset -  loss: 0.746146, accuracy: 0.811144\n\t\tTarget dataset -  loss: 1.068871, accuracy: 0.745587\n\nepoch:  14\n\tTrain:\n\t\terr_s_label: 0.123756, err_s_domain: 0.662605, err_t_domain: 0.661997, accuracy: 0.958622\n\tTest:\n\t\tSource dataset -  loss: 0.608003, accuracy: 0.840750\n\t\tTarget dataset -  loss: 0.950365, accuracy: 0.769584\n\nepoch:  15\n\tTrain:\n\t\terr_s_label: 0.115820, err_s_domain: 0.667955, err_t_domain: 0.669297, accuracy: 0.961685\n\tTest:\n\t\tSource dataset -  loss: 0.592417, accuracy: 0.845623\n\t\tTarget dataset -  loss: 1.035121, accuracy: 0.762229\n\nepoch:  16\n\tTrain:\n\t\terr_s_label: 0.109996, err_s_domain: 0.674683, err_t_domain: 0.675263, accuracy: 0.962859\n\tTest:\n\t\tSource dataset -  loss: 0.627703, accuracy: 0.845715\n\t\tTarget dataset -  loss: 0.944453, accuracy: 0.782825\n\nepoch:  17\n\tTrain:\n\t\terr_s_label: 0.100810, err_s_domain: 0.678549, err_t_domain: 0.678767, accuracy: 0.967073\n\tTest:\n\t\tSource dataset -  loss: 0.623085, accuracy: 0.845623\n\t\tTarget dataset -  loss: 0.987187, accuracy: 0.778687\n\nepoch:  18\n\tTrain:\n\t\terr_s_label: 0.096570, err_s_domain: 0.679670, err_t_domain: 0.680234, accuracy: 0.967142\n\tTest:\n\t\tSource dataset -  loss: 0.645464, accuracy: 0.844796\n\t\tTarget dataset -  loss: 0.881889, accuracy: 0.794134\n\nepoch:  19\n\tTrain:\n\t\terr_s_label: 0.085456, err_s_domain: 0.681693, err_t_domain: 0.681829, accuracy: 0.971471\n\tTest:\n\t\tSource dataset -  loss: 0.647669, accuracy: 0.846359\n\t\tTarget dataset -  loss: 0.945659, accuracy: 0.790272\n\nepoch:  20\n\tTrain:\n\t\terr_s_label: 0.083398, err_s_domain: 0.684252, err_t_domain: 0.684322, accuracy: 0.971609\n\tTest:\n\t\tSource dataset -  loss: 0.697622, accuracy: 0.835969\n\t\tTarget dataset -  loss: 0.948597, accuracy: 0.792019\n\nepoch:  21\n\tTrain:\n\t\terr_s_label: 0.077032, err_s_domain: 0.685543, err_t_domain: 0.685668, accuracy: 0.974441\n\tTest:\n\t\tSource dataset -  loss: 0.680778, accuracy: 0.841946\n\t\tTarget dataset -  loss: 0.951029, accuracy: 0.796065\n\nepoch:  22\n\tTrain:\n\t\terr_s_label: 0.072432, err_s_domain: 0.686130, err_t_domain: 0.686331, accuracy: 0.975961\n\tTest:\n\t\tSource dataset -  loss: 0.686586, accuracy: 0.843233\n\t\tTarget dataset -  loss: 0.835568, accuracy: 0.816752\n\nepoch:  23\n\tTrain:\n\t\terr_s_label: 0.067881, err_s_domain: 0.687981, err_t_domain: 0.688088, accuracy: 0.977688\n\tTest:\n\t\tSource dataset -  loss: 0.687707, accuracy: 0.844428\n\t\tTarget dataset -  loss: 0.855551, accuracy: 0.815373\n\nepoch:  24\n\tTrain:\n\t\terr_s_label: 0.063148, err_s_domain: 0.688743, err_t_domain: 0.688991, accuracy: 0.979668\n\tTest:\n\t\tSource dataset -  loss: 0.866865, accuracy: 0.816936\n\t\tTarget dataset -  loss: 1.055153, accuracy: 0.785123\n\nepoch:  25\n\tTrain:\n\t\terr_s_label: 0.066520, err_s_domain: 0.688782, err_t_domain: 0.688599, accuracy: 0.977941\n\tTest:\n\t\tSource dataset -  loss: 0.679285, accuracy: 0.848382\n\t\tTarget dataset -  loss: 0.878457, accuracy: 0.813902\n\nepoch:  26\n\tTrain:\n\t\terr_s_label: 0.055992, err_s_domain: 0.689648, err_t_domain: 0.689488, accuracy: 0.981648\n\tTest:\n\t\tSource dataset -  loss: 0.757498, accuracy: 0.838911\n\t\tTarget dataset -  loss: 0.989145, accuracy: 0.804983\n\nepoch:  27\n\tTrain:\n\t\terr_s_label: 0.058121, err_s_domain: 0.689738, err_t_domain: 0.689488, accuracy: 0.980727\n\tTest:\n\t\tSource dataset -  loss: 0.754882, accuracy: 0.839463\n\t\tTarget dataset -  loss: 0.958912, accuracy: 0.803604\n\nepoch:  28\n\tTrain:\n\t\terr_s_label: 0.051410, err_s_domain: 0.690186, err_t_domain: 0.689988, accuracy: 0.982569\n\tTest:\n\t\tSource dataset -  loss: 0.790990, accuracy: 0.835509\n\t\tTarget dataset -  loss: 0.903634, accuracy: 0.816936\n\nepoch:  29\n\tTrain:\n\t\terr_s_label: 0.052062, err_s_domain: 0.690222, err_t_domain: 0.690345, accuracy: 0.982477\n\tTest:\n\t\tSource dataset -  loss: 0.735796, accuracy: 0.845991\n\t\tTarget dataset -  loss: 0.870862, accuracy: 0.827050\n\nepoch:  30\n\tTrain:\n\t\terr_s_label: 0.048924, err_s_domain: 0.691110, err_t_domain: 0.690706, accuracy: 0.983513\n\tTest:\n\t\tSource dataset -  loss: 0.751899, accuracy: 0.843968\n\t\tTarget dataset -  loss: 0.918668, accuracy: 0.817488\n\nepoch:  31\n\tTrain:\n\t\terr_s_label: 0.042565, err_s_domain: 0.691440, err_t_domain: 0.691639, accuracy: 0.986092\n\tTest:\n\t\tSource dataset -  loss: 0.786036, accuracy: 0.847370\n\t\tTarget dataset -  loss: 0.916386, accuracy: 0.825671\n\nepoch:  32\n\tTrain:\n\t\terr_s_label: 0.044198, err_s_domain: 0.690824, err_t_domain: 0.690738, accuracy: 0.984987\n\tTest:\n\t\tSource dataset -  loss: 0.811248, accuracy: 0.840015\n\t\tTarget dataset -  loss: 0.984982, accuracy: 0.812799\n\nepoch:  33\n\tTrain:\n\t\terr_s_label: 0.042069, err_s_domain: 0.691431, err_t_domain: 0.691667, accuracy: 0.986115\n\tTest:\n\t\tSource dataset -  loss: 0.781527, accuracy: 0.841762\n\t\tTarget dataset -  loss: 0.922634, accuracy: 0.819327\n\nepoch:  34\n\tTrain:\n\t\terr_s_label: 0.043426, err_s_domain: 0.691633, err_t_domain: 0.691387, accuracy: 0.985125\n\tTest:\n\t\tSource dataset -  loss: 0.779735, accuracy: 0.847738\n\t\tTarget dataset -  loss: 0.914846, accuracy: 0.827786\n\nepoch:  35\n\tTrain:\n\t\terr_s_label: 0.040612, err_s_domain: 0.691378, err_t_domain: 0.691423, accuracy: 0.986438\n\tTest:\n\t\tSource dataset -  loss: 0.865194, accuracy: 0.838268\n\t\tTarget dataset -  loss: 1.069067, accuracy: 0.811420\n\nepoch:  36\n\tTrain:\n\t\terr_s_label: 0.037061, err_s_domain: 0.691557, err_t_domain: 0.691536, accuracy: 0.987290\n\tTest:\n\t\tSource dataset -  loss: 0.789489, accuracy: 0.848106\n\t\tTarget dataset -  loss: 0.899283, accuracy: 0.832751\n\nepoch:  37\n\tTrain:\n\t\terr_s_label: 0.037300, err_s_domain: 0.691943, err_t_domain: 0.691733, accuracy: 0.987727\n\tTest:\n\t\tSource dataset -  loss: 0.828562, accuracy: 0.840291\n\t\tTarget dataset -  loss: 0.939311, accuracy: 0.826407\n\nepoch:  38\n\tTrain:\n\t\terr_s_label: 0.038244, err_s_domain: 0.691554, err_t_domain: 0.691854, accuracy: 0.987543\n\tTest:\n\t\tSource dataset -  loss: 0.862869, accuracy: 0.839279\n\t\tTarget dataset -  loss: 1.001380, accuracy: 0.819603\n\nepoch:  39\n\tTrain:\n\t\terr_s_label: 0.035704, err_s_domain: 0.692445, err_t_domain: 0.692349, accuracy: 0.988165\n\tTest:\n\t\tSource dataset -  loss: 0.844694, accuracy: 0.836429\n\t\tTarget dataset -  loss: 0.972737, accuracy: 0.823097\n\nepoch:  40\n\tTrain:\n\t\terr_s_label: 0.037437, err_s_domain: 0.691805, err_t_domain: 0.691933, accuracy: 0.987658\n\tTest:\n\t\tSource dataset -  loss: 0.834048, accuracy: 0.847922\n\t\tTarget dataset -  loss: 0.943162, accuracy: 0.833303\n\nepoch:  41\n\tTrain:\n\t\terr_s_label: 0.035666, err_s_domain: 0.692419, err_t_domain: 0.692466, accuracy: 0.988878\n\tTest:\n\t\tSource dataset -  loss: 0.882241, accuracy: 0.839095\n\t\tTarget dataset -  loss: 1.006263, accuracy: 0.823373\n\nepoch:  43\n\tTrain:\n\t\terr_s_label: 0.031907, err_s_domain: 0.692384, err_t_domain: 0.692337, accuracy: 0.989822\n\tTest:\n\t\tSource dataset -  loss: 0.892063, accuracy: 0.840658\n\t\tTarget dataset -  loss: 1.006891, accuracy: 0.826775\n\nepoch:  44\n\tTrain:\n\t\terr_s_label: 0.033235, err_s_domain: 0.692296, err_t_domain: 0.692210, accuracy: 0.989040\n\tTest:\n\t\tSource dataset -  loss: 0.926002, accuracy: 0.834498\n\t\tTarget dataset -  loss: 1.011872, accuracy: 0.824660\n\nepoch:  45\n\tTrain:\n\t\terr_s_label: 0.035123, err_s_domain: 0.692479, err_t_domain: 0.692546, accuracy: 0.988878\n\tTest:\n\t\tSource dataset -  loss: 0.970278, accuracy: 0.826683\n\t\tTarget dataset -  loss: 1.036556, accuracy: 0.820338\n\nepoch:  46\n\tTrain:\n\t\terr_s_label: 0.035223, err_s_domain: 0.692286, err_t_domain: 0.692218, accuracy: 0.988142\n\tTest:\n\t\tSource dataset -  loss: 0.894580, accuracy: 0.841670\n\t\tTarget dataset -  loss: 0.976738, accuracy: 0.832291\n\nepoch:  47\n\tTrain:\n\t\terr_s_label: 0.029828, err_s_domain: 0.692535, err_t_domain: 0.692565, accuracy: 0.990398\n\tTest:\n\t\tSource dataset -  loss: 0.887073, accuracy: 0.842681\n\t\tTarget dataset -  loss: 0.976739, accuracy: 0.829717\n\nepoch:  48\n\tTrain:\n\t\terr_s_label: 0.029821, err_s_domain: 0.692529, err_t_domain: 0.692364, accuracy: 0.989845\n\tTest:\n\t\tSource dataset -  loss: 0.907099, accuracy: 0.843049\n\t\tTarget dataset -  loss: 1.015903, accuracy: 0.828981\n\nepoch:  49\n\tTrain:\n\t\terr_s_label: 0.030205, err_s_domain: 0.692549, err_t_domain: 0.692595, accuracy: 0.990744\n\tTest:\n\t\tSource dataset -  loss: 0.974856, accuracy: 0.831924\n\t\tTarget dataset -  loss: 1.034329, accuracy: 0.823924\n\nepoch:  50\n\tTrain:\n\t\terr_s_label: 0.026935, err_s_domain: 0.692643, err_t_domain: 0.692637, accuracy: 0.990605\n\tTest:\n\t\tSource dataset -  loss: 0.960242, accuracy: 0.837624\n\t\tTarget dataset -  loss: 1.005371, accuracy: 0.833579\n\nepoch:  51\n\tTrain:\n\t\terr_s_label: 0.028802, err_s_domain: 0.692722, err_t_domain: 0.692721, accuracy: 0.990306\n\tTest:\n\t\tSource dataset -  loss: 0.936757, accuracy: 0.842129\n\t\tTarget dataset -  loss: 1.007219, accuracy: 0.833119\n\nepoch:  52\n\tTrain:\n\t\terr_s_label: 0.023763, err_s_domain: 0.692884, err_t_domain: 0.692979, accuracy: 0.992056\n\tTest:\n\t\tSource dataset -  loss: 0.916396, accuracy: 0.845715\n\t\tTarget dataset -  loss: 1.004104, accuracy: 0.834774\n\nepoch:  53\n\tTrain:\n\t\terr_s_label: 0.025310, err_s_domain: 0.692577, err_t_domain: 0.692604, accuracy: 0.991757\n\tTest:\n\t\tSource dataset -  loss: 0.912452, accuracy: 0.842313\n\t\tTarget dataset -  loss: 0.986261, accuracy: 0.833211\n\nepoch:  54\n\tTrain:\n\t\terr_s_label: 0.025769, err_s_domain: 0.692517, err_t_domain: 0.692465, accuracy: 0.991066\n\tTest:\n\t\tSource dataset -  loss: 0.934402, accuracy: 0.842129\n\t\tTarget dataset -  loss: 1.041541, accuracy: 0.829441\n\nepoch:  55\n\tTrain:\n\t\terr_s_label: 0.026443, err_s_domain: 0.692845, err_t_domain: 0.692662, accuracy: 0.991365\n\tTest:\n\t\tSource dataset -  loss: 0.927988, accuracy: 0.846543\n\t\tTarget dataset -  loss: 1.030436, accuracy: 0.833579\n\nepoch:  56\n\tTrain:\n\t\terr_s_label: 0.031093, err_s_domain: 0.692575, err_t_domain: 0.692769, accuracy: 0.991204\n\tTest:\n\t\tSource dataset -  loss: 1.001115, accuracy: 0.834406\n\t\tTarget dataset -  loss: 1.105884, accuracy: 0.825303\n\nepoch:  57\n\tTrain:\n\t\terr_s_label: 0.026937, err_s_domain: 0.692827, err_t_domain: 0.692829, accuracy: 0.991595\n\tTest:\n\t\tSource dataset -  loss: 0.996618, accuracy: 0.832935\n\t\tTarget dataset -  loss: 1.059296, accuracy: 0.825947\n\nepoch:  58\n\tTrain:\n\t\terr_s_label: 0.022286, err_s_domain: 0.692683, err_t_domain: 0.692810, accuracy: 0.992263\n\tTest:\n\t\tSource dataset -  loss: 0.977983, accuracy: 0.837808\n\t\tTarget dataset -  loss: 1.073034, accuracy: 0.828705\n\nepoch:  59\n\tTrain:\n\t\terr_s_label: 0.023509, err_s_domain: 0.692885, err_t_domain: 0.692876, accuracy: 0.992770\n\tTest:\n\t\tSource dataset -  loss: 0.981740, accuracy: 0.838544\n\t\tTarget dataset -  loss: 1.068909, accuracy: 0.829165\n\nepoch:  60\n\tTrain:\n\t\terr_s_label: 0.026029, err_s_domain: 0.692635, err_t_domain: 0.692634, accuracy: 0.991043\n\tTest:\n\t\tSource dataset -  loss: 0.951307, accuracy: 0.845991\n\t\tTarget dataset -  loss: 1.072977, accuracy: 0.832199\n\nepoch:  61\n\tTrain:\n\t\terr_s_label: 0.024674, err_s_domain: 0.693026, err_t_domain: 0.692842, accuracy: 0.992010\n\tTest:\n\t\tSource dataset -  loss: 0.994162, accuracy: 0.839923\n\t\tTarget dataset -  loss: 1.068935, accuracy: 0.833119\n\nepoch:  62\n\tTrain:\n\t\terr_s_label: 0.024488, err_s_domain: 0.692871, err_t_domain: 0.692891, accuracy: 0.991734\n\tTest:\n\t\tSource dataset -  loss: 0.959899, accuracy: 0.841394\n\t\tTarget dataset -  loss: 1.025993, accuracy: 0.833579\n\nepoch:  63\n\tTrain:\n\t\terr_s_label: 0.023976, err_s_domain: 0.692786, err_t_domain: 0.692871, accuracy: 0.991941\n\tTest:\n\t\tSource dataset -  loss: 1.029742, accuracy: 0.838084\n\t\tTarget dataset -  loss: 1.146800, accuracy: 0.825395\n\nepoch:  64\n\tTrain:\n\t\terr_s_label: 0.022829, err_s_domain: 0.692865, err_t_domain: 0.693041, accuracy: 0.992517\n\tTest:\n\t\tSource dataset -  loss: 0.970692, accuracy: 0.839923\n\t\tTarget dataset -  loss: 1.033284, accuracy: 0.835877\n\nepoch:  65\n\tTrain:\n\t\terr_s_label: 0.022031, err_s_domain: 0.693067, err_t_domain: 0.692904, accuracy: 0.992793\n\tTest:\n\t\tSource dataset -  loss: 1.029161, accuracy: 0.833211\n\t\tTarget dataset -  loss: 1.122939, accuracy: 0.822729\n\nepoch:  66\n\tTrain:\n\t\terr_s_label: 0.020156, err_s_domain: 0.692957, err_t_domain: 0.693033, accuracy: 0.992816\n\tTest:\n\t\tSource dataset -  loss: 0.995460, accuracy: 0.842405\n\t\tTarget dataset -  loss: 1.090060, accuracy: 0.831832\n\nepoch:  67\n\tTrain:\n\t\terr_s_label: 0.020820, err_s_domain: 0.692859, err_t_domain: 0.692841, accuracy: 0.993230\n\tTest:\n\t\tSource dataset -  loss: 1.165051, accuracy: 0.827510\n\t\tTarget dataset -  loss: 1.256141, accuracy: 0.821074\n\nepoch:  68\n\tTrain:\n\t\terr_s_label: 0.023379, err_s_domain: 0.693082, err_t_domain: 0.693111, accuracy: 0.992724\n\tTest:\n\t\tSource dataset -  loss: 1.007967, accuracy: 0.843509\n\t\tTarget dataset -  loss: 1.081168, accuracy: 0.836337\n\nepoch:  69\n\tTrain:\n\t\terr_s_label: 0.021102, err_s_domain: 0.692877, err_t_domain: 0.692729, accuracy: 0.992724\n\tTest:\n\t\tSource dataset -  loss: 1.075605, accuracy: 0.837716\n\t\tTarget dataset -  loss: 1.186291, accuracy: 0.826591\n\nepoch:  70\n\tTrain:\n\t\terr_s_label: 0.022925, err_s_domain: 0.692786, err_t_domain: 0.692970, accuracy: 0.992286\n\tTest:\n\t\tSource dataset -  loss: 1.058069, accuracy: 0.832107\n\t\tTarget dataset -  loss: 1.182488, accuracy: 0.816936\n\nepoch:  71\n\tTrain:\n\t\terr_s_label: 0.020871, err_s_domain: 0.693012, err_t_domain: 0.692919, accuracy: 0.992563\n\tTest:\n\t\tSource dataset -  loss: 1.038722, accuracy: 0.841026\n\t\tTarget dataset -  loss: 1.094855, accuracy: 0.833946\n\nepoch:  72\n\tTrain:\n\t\terr_s_label: 0.020420, err_s_domain: 0.692863, err_t_domain: 0.692823, accuracy: 0.994220\n\tTest:\n\t\tSource dataset -  loss: 1.068002, accuracy: 0.832291\n\t\tTarget dataset -  loss: 1.179024, accuracy: 0.823832\n\nepoch:  73\n\tTrain:\n\t\terr_s_label: 0.020772, err_s_domain: 0.693149, err_t_domain: 0.693121, accuracy: 0.992816\n\tTest:\n\t\tSource dataset -  loss: 0.978704, accuracy: 0.844980\n\t\tTarget dataset -  loss: 1.044498, accuracy: 0.839555\n\nepoch:  74\n\tTrain:\n\t\terr_s_label: 0.017257, err_s_domain: 0.693093, err_t_domain: 0.693187, accuracy: 0.994220\n\tTest:\n\t\tSource dataset -  loss: 1.018263, accuracy: 0.838636\n\t\tTarget dataset -  loss: 1.089959, accuracy: 0.829717\n\nepoch:  75\n\tTrain:\n\t\terr_s_label: 0.023103, err_s_domain: 0.692588, err_t_domain: 0.692542, accuracy: 0.992125\n\tTest:\n\t\tSource dataset -  loss: 0.994992, accuracy: 0.846727\n\t\tTarget dataset -  loss: 1.099398, accuracy: 0.834498\n\nepoch:  76\n\tTrain:\n\t\terr_s_label: 0.021154, err_s_domain: 0.693005, err_t_domain: 0.693012, accuracy: 0.992954\n\tTest:\n\t\tSource dataset -  loss: 1.052190, accuracy: 0.836981\n\t\tTarget dataset -  loss: 1.135802, accuracy: 0.827418\n\nepoch:  77\n\tTrain:\n\t\terr_s_label: 0.019608, err_s_domain: 0.693064, err_t_domain: 0.693015, accuracy: 0.993345\n\tTest:\n\t\tSource dataset -  loss: 1.045385, accuracy: 0.845164\n\t\tTarget dataset -  loss: 1.103456, accuracy: 0.836889\n\nepoch:  78\n\tTrain:\n\t\terr_s_label: 0.017675, err_s_domain: 0.693033, err_t_domain: 0.692959, accuracy: 0.994243\n\tTest:\n\t\tSource dataset -  loss: 1.122325, accuracy: 0.833579\n\t\tTarget dataset -  loss: 1.181214, accuracy: 0.824476\n\nepoch:  79\n\tTrain:\n\t\terr_s_label: 0.020457, err_s_domain: 0.692940, err_t_domain: 0.692999, accuracy: 0.992862\n\tTest:\n\t\tSource dataset -  loss: 1.116576, accuracy: 0.835601\n\t\tTarget dataset -  loss: 1.230186, accuracy: 0.823373\n\nepoch:  80\n\tTrain:\n\t\terr_s_label: 0.020573, err_s_domain: 0.693052, err_t_domain: 0.693073, accuracy: 0.992885\n\tTest:\n\t\tSource dataset -  loss: 1.157678, accuracy: 0.829717\n\t\tTarget dataset -  loss: 1.277618, accuracy: 0.817028\n\nepoch:  81\n\tTrain:\n\t\terr_s_label: 0.016383, err_s_domain: 0.693010, err_t_domain: 0.692989, accuracy: 0.994405\n\tTest:\n\t\tSource dataset -  loss: 1.060936, accuracy: 0.838636\n\t\tTarget dataset -  loss: 1.118134, accuracy: 0.834130\n\nepoch:  82\n\tTrain:\n\t\terr_s_label: 0.016070, err_s_domain: 0.693134, err_t_domain: 0.693142, accuracy: 0.994589\n\tTest:\n\t\tSource dataset -  loss: 1.062095, accuracy: 0.842957\n\t\tTarget dataset -  loss: 1.142583, accuracy: 0.835325\n\nepoch:  83\n\tTrain:\n\t\terr_s_label: 0.019225, err_s_domain: 0.692943, err_t_domain: 0.692860, accuracy: 0.994451\n\tTest:\n\t\tSource dataset -  loss: 1.096777, accuracy: 0.837164\n\t\tTarget dataset -  loss: 1.207510, accuracy: 0.827786\n\nepoch:  84\n\tTrain:\n\t\terr_s_label: 0.021863, err_s_domain: 0.692961, err_t_domain: 0.692973, accuracy: 0.993392\n\tTest:\n\t\tSource dataset -  loss: 1.058745, accuracy: 0.840199\n\t\tTarget dataset -  loss: 1.126110, accuracy: 0.834774\n\nepoch:  85\n\tTrain:\n\t\terr_s_label: 0.017921, err_s_domain: 0.692965, err_t_domain: 0.692976, accuracy: 0.994197\n\tTest:\n\t\tSource dataset -  loss: 1.004740, accuracy: 0.845164\n\t\tTarget dataset -  loss: 1.102029, accuracy: 0.835050\n\nepoch:  86\n\tTrain:\n\t\terr_s_label: 0.016628, err_s_domain: 0.692956, err_t_domain: 0.693058, accuracy: 0.994658\n\tTest:\n\t\tSource dataset -  loss: 1.092568, accuracy: 0.836981\n\t\tTarget dataset -  loss: 1.121984, accuracy: 0.836337\n\nepoch:  87\n\tTrain:\n\t\terr_s_label: 0.019704, err_s_domain: 0.692936, err_t_domain: 0.692917, accuracy: 0.993322\n\tTest:\n\t\tSource dataset -  loss: 1.062379, accuracy: 0.842865\n\t\tTarget dataset -  loss: 1.126302, accuracy: 0.834774\n\nepoch:  88\n\tTrain:\n\t\terr_s_label: 0.016605, err_s_domain: 0.693194, err_t_domain: 0.693227, accuracy: 0.994105\n\tTest:\n\t\tSource dataset -  loss: 1.052002, accuracy: 0.844520\n\t\tTarget dataset -  loss: 1.127822, accuracy: 0.835325\n\nepoch:  89\n\tTrain:\n\t\terr_s_label: 0.015127, err_s_domain: 0.692922, err_t_domain: 0.692937, accuracy: 0.994934\n\tTest:\n\t\tSource dataset -  loss: 1.062048, accuracy: 0.846451\n\t\tTarget dataset -  loss: 1.148167, accuracy: 0.834866\n\nepoch:  90\n\tTrain:\n\t\terr_s_label: 0.017841, err_s_domain: 0.693163, err_t_domain: 0.693132, accuracy: 0.994243\n\tTest:\n\t\tSource dataset -  loss: 1.055596, accuracy: 0.845348\n\t\tTarget dataset -  loss: 1.120282, accuracy: 0.838911\n\nepoch:  91\n\tTrain:\n\t\terr_s_label: 0.016794, err_s_domain: 0.693078, err_t_domain: 0.692965, accuracy: 0.994174\n\tTest:\n\t\tSource dataset -  loss: 1.111343, accuracy: 0.836521\n\t\tTarget dataset -  loss: 1.138047, accuracy: 0.833027\n\nepoch:  92\n\tTrain:\n\t\terr_s_label: 0.017124, err_s_domain: 0.692833, err_t_domain: 0.692841, accuracy: 0.994612\n\tTest:\n\t\tSource dataset -  loss: 1.099244, accuracy: 0.836797\n\t\tTarget dataset -  loss: 1.156545, accuracy: 0.833670\n\nepoch:  93\n\tTrain:\n\t\terr_s_label: 0.017596, err_s_domain: 0.693305, err_t_domain: 0.693288, accuracy: 0.994405\n\tTest:\n\t\tSource dataset -  loss: 1.131320, accuracy: 0.834130\n\t\tTarget dataset -  loss: 1.214418, accuracy: 0.824108\n\nepoch:  94\n\tTrain:\n\t\terr_s_label: 0.016621, err_s_domain: 0.693020, err_t_domain: 0.693052, accuracy: 0.995211\n\tTest:\n\t\tSource dataset -  loss: 1.198700, accuracy: 0.828797\n\t\tTarget dataset -  loss: 1.257058, accuracy: 0.823465\n\nepoch:  95\n\tTrain:\n\t\terr_s_label: 0.017989, err_s_domain: 0.693040, err_t_domain: 0.693067, accuracy: 0.994635\n\tTest:\n\t\tSource dataset -  loss: 1.152747, accuracy: 0.834314\n\t\tTarget dataset -  loss: 1.197799, accuracy: 0.832659\n\nepoch:  96\n\tTrain:\n\t\terr_s_label: 0.014821, err_s_domain: 0.693126, err_t_domain: 0.693030, accuracy: 0.994980\n\tTest:\n\t\tSource dataset -  loss: 1.122658, accuracy: 0.839095\n\t\tTarget dataset -  loss: 1.197664, accuracy: 0.831188\n\nepoch:  97\n\tTrain:\n\t\terr_s_label: 0.017140, err_s_domain: 0.692949, err_t_domain: 0.693004, accuracy: 0.994243\n\tTest:\n\t\tSource dataset -  loss: 1.157414, accuracy: 0.836797\n\t\tTarget dataset -  loss: 1.253589, accuracy: 0.826499\n\nepoch:  98\n\tTrain:\n\t\terr_s_label: 0.015371, err_s_domain: 0.692916, err_t_domain: 0.692903, accuracy: 0.994819\n\tTest:\n\t\tSource dataset -  loss: 1.105122, accuracy: 0.840750\n\t\tTarget dataset -  loss: 1.194447, accuracy: 0.831280\n\nepoch:  99\n\tTrain:\n\t\terr_s_label: 0.014255, err_s_domain: 0.693152, err_t_domain: 0.693209, accuracy: 0.995049\n\tTest:\n\t\tSource dataset -  loss: 1.100410, accuracy: 0.842589\n\t\tTarget dataset -  loss: 1.162923, accuracy: 0.835785\n\nepoch:  100\n\tTrain:\n\t\terr_s_label: 0.016476, err_s_domain: 0.693129, err_t_domain: 0.693011, accuracy: 0.994704\n\tTest:\n\t\tSource dataset -  loss: 1.156826, accuracy: 0.837992\n\t\tTarget dataset -  loss: 1.243362, accuracy: 0.829901\nTRAINING COMPLETED\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Graphs","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Plotting training and test losses\nplt.figure(figsize=(12, 5))\n\n# Plot training losses\nplt.subplot(1, 2, 1)\nplt.plot(train_losses_s_label, label='Source Label Loss')\nplt.plot(train_losses_s_domain, label='Source Domain Loss')\nplt.plot(train_losses_t_domain, label='Target Domain Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Training Losses')\nplt.legend()\n\n# Plot test losses\nplt.subplot(1, 2, 2)\nplt.plot(test_losses_source, label='Source Test Loss')\nplt.plot(test_losses_target, label='Target Test Loss')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Test Losses')\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n\n# Plotting training and test accuracies\nplt.figure(figsize=(12, 5))\n\n# Plot training accuracy\nplt.subplot(1, 2, 1)\nplt.plot(train_accs, label='Training Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Training Accuracy')\nplt.legend()\n\n# Plot test accuracy\nplt.subplot(1, 2, 2)\nplt.plot(test_accs_source, label='Source Test Accuracy')\nplt.plot(test_accs_target, label='Target Test Accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.title('Test Accuracy')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-06T18:20:03.700683Z","iopub.execute_input":"2024-07-06T18:20:03.701015Z","iopub.status.idle":"2024-07-06T18:20:04.281062Z","shell.execute_reply.started":"2024-07-06T18:20:03.700987Z","shell.execute_reply":"2024-07-06T18:20:04.279639Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Plot training losses\u001b[39;00m\n\u001b[1;32m      7\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m----> 8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_losses_s_label\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource Label Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses_s_domain, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource Domain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     10\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(train_losses_t_domain, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTarget Domain Loss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","\u001b[0;31mNameError\u001b[0m: name 'train_losses_s_label' is not defined"],"ename":"NameError","evalue":"name 'train_losses_s_label' is not defined","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1200x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}